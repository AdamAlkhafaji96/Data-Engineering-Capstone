{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data Pipelines for United States International Visitor Air Travel Data\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "+ SUMMARY: This project gathers I94 Immigration data for International travel to the United States, US cities demographics data, and airport codes data in and creates a data pipeline which uses Spark in order to create a data model that includes Fact and Dimension tables for analyzing data relating to Air travel to the United States.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, LongType, TimestampType\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc.\n",
    "\n",
    "`Initially the raw data will be loaded into the project workspace.`\n",
    "\n",
    "`This project creates a data pipeline which extracts the following datasets:`\n",
    "\n",
    "* I94 Immigration data\n",
    "* US cities demographics data\n",
    "* Airport codes data\n",
    "\n",
    "`Using Spark, the data will then be cleaned and transformed into  a data model consisting of fact and dimension tables.`\n",
    "\n",
    "`Finally, the analytics tables with clean data will be written to parquet files which can be read and analyzed using Spark or copied into a data warehouse such as Amazon Redshift for analysis.`\n",
    "\n",
    "`Data quality checks will be applied at various stages in the pipeline to ensure the data is loaded correctly and is of high quality.`\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1. I94 Immigration Data\n",
    "\n",
    "* Contains international visitor arrival data by world regions and select countries (including top 20), type of visa, mode of transportation, age groups, states visited (first intended address only), and the top ports of entry for select countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data to a Pandas dataframe here\n",
    "df = pd.read_sas('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat', encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "1      NaN   ...           Y      NaN   1991.0       D/S      M    NaN   \n",
       "2  20691.0   ...         NaN        M   1961.0  09302016      M    NaN   \n",
       "3  20567.0   ...         NaN        M   1988.0  09302016    NaN    NaN   \n",
       "4  20567.0   ...         NaN        M   2012.0  09302016    NaN    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0     NaN  1.897628e+09    NaN       B2  \n",
       "1     NaN  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2. Airport Codes Data\n",
    "\n",
    "* This is a simple table of airport codes and corresponding cities.\n",
    "\n",
    "* The airport codes may refer to either IATA airport code, a three-letter code which is used in passenger reservation, ticketing and baggage-handling systems, or the ICAO airport code which is a four letter code used by ATC systems and for airports that do not have an IATA airport code (from wikipedia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport_code_df = pd.read_csv('airport-codes_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_code_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3. US Cities Demographics Data\n",
    "\n",
    "* This dataset contains information about the demographics of all US cities and census-designated places with a population greater or equal to 65,000. \n",
    "\n",
    "* This data comes from the US Census Bureau's 2015 American Community Survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_cities_df = pd.read_csv('us-cities-demographics.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_cities_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4. Country Codes Data\n",
    "\n",
    "* This dataset contains information that relates the country ID from the I94 Immigration dataset to the full name of the country. \n",
    "\n",
    "* This data comes from the I94_SAS_Labels_Descriptions.SAS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_df = pd.read_csv('country_codes.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94_res</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i94_res                                            country\n",
       "0      582  MEXICO Air Sea, and Not Reported (I-94, no lan...\n",
       "1      236                                        AFGHANISTAN\n",
       "2      101                                            ALBANIA\n",
       "3      316                                            ALGERIA\n",
       "4      102                                            ANDORRA"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Checking for Null Airport ID (ident)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    55075\n",
       "Name: ident, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_code_df['ident'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Checking for Null iata_code\n",
    "+ Will need to drop records with Null iata_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     45886\n",
       "False     9189\n",
       "Name: iata_code, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_code_df['iata_code'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Counting number of each type of airport\n",
    "+ Data model will include only airports classified as small_aiport, medium_airport, large_airport, or closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "small_airport     33965\n",
       "heliport          11287\n",
       "medium_airport     4550\n",
       "closed             3606\n",
       "seaplane_base      1016\n",
       "large_airport       627\n",
       "balloonport          24\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_code_df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Checking number of records where the airline is Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3012686\n",
       "True       83627\n",
       "Name: airline, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Counting each state's population by race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "pop_df = us_cities_df[['State','Race','Count']].groupby([\"State\",\"Race\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "pop_df2 = pop_df[['State','Race','Count']].sum(level=\"Race\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th>Race</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Alabama</th>\n",
       "      <th>American Indian and Alaska Native</th>\n",
       "      <td>8084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>28769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black or African-American</th>\n",
       "      <td>521068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic or Latino</th>\n",
       "      <td>39313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>498920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Count\n",
       "State   Race                                     \n",
       "Alabama American Indian and Alaska Native    8084\n",
       "        Asian                               28769\n",
       "        Black or African-American          521068\n",
       "        Hispanic or Latino                  39313\n",
       "        White                              498920"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Checking each data set for duplicates\n",
    "+ Will drop all duplicate records in later steps if found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3096313\n",
      "3096313\n"
     ]
    }
   ],
   "source": [
    "print(len(df.index))\n",
    "df2 = df.drop_duplicates()\n",
    "print(len(df2.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2891\n",
      "2891\n"
     ]
    }
   ],
   "source": [
    "print(len(us_cities_df.index))\n",
    "us_cities_df2 = us_cities_df.drop_duplicates()\n",
    "print(len(us_cities_df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55075\n",
      "55075\n"
     ]
    }
   ],
   "source": [
    "print(len(airport_code_df.index))\n",
    "airport_code_df2 = airport_code_df.drop_duplicates()\n",
    "print(len(airport_code_df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Top 10 most common iata_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      80\n",
       "PRI     3\n",
       "OHE     3\n",
       "SVD     2\n",
       "CQP     2\n",
       "KYF     2\n",
       "SHO     2\n",
       "DLR     2\n",
       "RCH     2\n",
       "RZS     2\n",
       "Name: iata_code, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_code_df['iata_code'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Unique Airport types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['heliport', 'small_airport', 'closed', 'seaplane_base',\n",
       "       'balloonport', 'medium_airport', 'large_airport'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_code_df['type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Top 10 most common destination cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NYC    485916\n",
       "MIA    343941\n",
       "LOS    310163\n",
       "SFR    152586\n",
       "ORL    149195\n",
       "HHW    142720\n",
       "NEW    136122\n",
       "CHI    130564\n",
       "HOU    101481\n",
       "FTL     95977\n",
       "Name: i94port, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['i94port'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Steps\n",
    "##### The following steps will be applied to clean the raw data:\n",
    "1. Airport data will be filtered to only include airports of types small airport, medium airport, large airport, and closed. Additionally, the final airports table will only include airports with a valid IATA code.\n",
    "2. Travelers table will be created by selecting only travelers who have either a valid flight number or a valid airline since we are creating data model only based on air travel data.\n",
    "3. Travel records with an invalid destination city or destination state will be removed.\n",
    "4. Population data will be aggregated to include the total population, male population, female populaiton, and foreign-born population totals for each state.\n",
    "5. Data types will be cast to the desired types based on the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "1. Read the data from source files into Spark Dataframes\n",
    "2. Performing data cleaning steps to handle unwanted data\n",
    "3. Join and transform data into fact and dimension tables\n",
    "4. Run data quality checks to ensure the fact and dimension tables are created correctly and contain records\n",
    "5. Write final fact and dimension tables to destination folders stored as parquet files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Load data into Spark for cleaning and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "#df_spark =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_schema = StructType([\n",
    "        StructField(\"cicid\", LongType()),\n",
    "        StructField(\"i94res\", LongType()),\n",
    "        StructField(\"i94addr\", StringType()),\n",
    "        StructField(\"visapost\", StringType()),\n",
    "        StructField(\"i94r\", LongType()),\n",
    "        StructField(\"i94mon\", LongType()),\n",
    "        StructField(\"arrdate\", LongType()),\n",
    "        StructField(\"depdate\", LongType()),\n",
    "        StructField(\"dtadfile\", StringType()),\n",
    "        StructField(\"dtaddto\", StringType()),\n",
    "        StructField(\"i94port\", StringType()),\n",
    "        StructField(\"traveler_id\", LongType()),\n",
    "        StructField(\"birth_year\", StringType()),\n",
    "        StructField(\"age\", LongType()),\n",
    "        StructField(\"gender\", StringType()),\n",
    "        StructField(\"airline\", StringType()),\n",
    "        StructField(\"flight_no\", StringType()),\n",
    "        StructField(\"visa_type\", StringType())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "#df_spark.write.parquet(\"sas_data\")\n",
    "df_spark=spark.read.options(schema=i94_schema, header='True').parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create airports Dimension Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airports_dim_schema = StructType([\n",
    "        StructField(\"airport_id\", StringType()),\n",
    "        StructField(\"iata_code\", StringType()),\n",
    "        StructField(\"airport_type\", StringType()),\n",
    "        StructField(\"airport_name\", StringType()),\n",
    "        StructField(\"municipality\", StringType()),\n",
    "        StructField(\"iso_region\", StringType()),\n",
    "        StructField(\"coordinates\", StringType()),        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airports_spark = spark.read.options(delimiter=',',schema=airports_dim_schema, header='True').csv('airport-codes_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airports_stg = airports_spark.select('ident','iata_code','type','name','municipality','iso_region','coordinates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airports_stg = airports_stg.createOrReplaceTempView(\"airports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airports_dim = spark.sql(\"\"\"SELECT \n",
    "                ident as airport_id, \n",
    "                iata_code, \n",
    "                type as airport_type, \n",
    "                name as airport_name, \n",
    "                municipality, \n",
    "                iso_region,\n",
    "                coordinates \n",
    "            FROM airports WHERE type in ('small_airport','medium_airport','large_airport','closed')\n",
    "            AND iata_code is not null\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+--------------------+---------------+----------+--------------------+\n",
      "|airport_id|iata_code| airport_type|        airport_name|   municipality|iso_region|         coordinates|\n",
      "+----------+---------+-------------+--------------------+---------------+----------+--------------------+\n",
      "|       03N|      UTK|small_airport|      Utirik Airport|  Utirik Island|    MH-UTI|  169.852005, 11.222|\n",
      "|      07FA|      OCA|small_airport|Ocean Reef Club A...|      Key Largo|     US-FL|-80.274803161621,...|\n",
      "|       0AK|      PQS|small_airport|Pilot Station Air...|  Pilot Station|     US-AK|-162.899994, 61.9...|\n",
      "|      0CO2|      CSE|small_airport|Crested Butte Air...|  Crested Butte|     US-CO|-106.928341, 38.8...|\n",
      "|      0TE7|      JCY|small_airport|   LBJ Ranch Airport|   Johnson City|     US-TX|-98.6224975585999...|\n",
      "|      13MA|      PMX|small_airport|Metropolitan Airport|         Palmer|     US-MA|-72.3114013671999...|\n",
      "|       16A|      NUP|small_airport| Nunapitchuk Airport|    Nunapitchuk|     US-AK|-162.440454, 60.9...|\n",
      "|      19AK|      ICY|small_airport|     Icy Bay Airport|        Icy Bay|     US-AK|-141.662002563, 5...|\n",
      "|       1KC|      KKK|small_airport|Kalakaket Creek A...|Kalakaket Creek|     US-AK|-156.820392609, 6...|\n",
      "|       1O6|      MHS|small_airport|Dunsmuir Muni-Mot...|       Dunsmuir|     US-CA|-122.272003, 41.2...|\n",
      "+----------+---------+-------------+--------------------+---------------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airports_dim.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create travelers Dimension Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "travelers_spark = df_spark.select('cicid','biryear','i94bir','gender','airline','fltno','visatype','visapost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "travelers_stg = travelers_spark.createOrReplaceTempView(\"travelers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "travelers_dim = spark.sql(\"\"\"SELECT \n",
    "                cast(cicid as bigint) as traveler_id, \n",
    "                cast(biryear as int) as birth_year, \n",
    "                cast(i94bir as int) as age, \n",
    "                gender, \n",
    "                airline, \n",
    "                fltno as flight_no, \n",
    "                visatype as visa_type \n",
    "              FROM travelers\n",
    "              WHERE airline is not null\n",
    "              OR fltno is not null\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---+------+-------+---------+---------+\n",
      "|traveler_id|birth_year|age|gender|airline|flight_no|visa_type|\n",
      "+-----------+----------+---+------+-------+---------+---------+\n",
      "|    5748517|      1976| 40|     F|     QF|    00011|       B1|\n",
      "|    5748518|      1984| 32|     F|     VA|    00007|       B1|\n",
      "|    5748519|      1987| 29|     M|     DL|    00040|       B1|\n",
      "|    5748520|      1987| 29|     F|     DL|    00040|       B1|\n",
      "|    5748521|      1988| 28|     M|     DL|    00040|       B1|\n",
      "|    5748522|      1959| 57|     M|     NZ|    00010|       B2|\n",
      "|    5748523|      1950| 66|     F|     NZ|    00010|       B2|\n",
      "|    5748524|      1975| 41|     F|     NZ|    00010|       B2|\n",
      "|    5748525|      1989| 27|     M|     NZ|    00028|       B2|\n",
      "|    5748526|      1990| 26|     F|     NZ|    00002|       B2|\n",
      "+-----------+----------+---+------+-------+---------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "travelers_dim.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create travel Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "travel_spark = df_spark.select('cicid','i94res','i94addr','visapost','i94yr','i94mon','arrdate','depdate','dtadfile','dtaddto','i94port')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "travel_stg = travel_spark.createOrReplaceTempView(\"travel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "travel = spark.sql(\"\"\"SELECT \n",
    "                cast(cicid as bigint) as traveler_id, \n",
    "                cast(i94res as int) as country_id,\n",
    "                i94addr as state_code,\n",
    "                i94port as destination_city,\n",
    "                cast(i94yr as int) as year, \n",
    "                cast(i94mon as int) as month, \n",
    "                cast(arrdate as int) as arrival_date, \n",
    "                cast(depdate as int) as departure_date, \n",
    "                dtadfile as file_create_dt, \n",
    "                dtaddto as admitted_until_dt \n",
    "              FROM travel WHERE i94addr is not NULL\n",
    "              AND i94port is not null\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+----------------+----+-----+------------+--------------+--------------+-----------------+\n",
      "|traveler_id|country_id|state_code|destination_city|year|month|arrival_date|departure_date|file_create_dt|admitted_until_dt|\n",
      "+-----------+----------+----------+----------------+----+-----+------------+--------------+--------------+-----------------+\n",
      "|    5748517|       438|        CA|             LOS|2016|    4|       20574|         20582|      20160430|         10292016|\n",
      "|    5748518|       438|        NV|             LOS|2016|    4|       20574|         20591|      20160430|         10292016|\n",
      "|    5748519|       438|        WA|             LOS|2016|    4|       20574|         20582|      20160430|         10292016|\n",
      "|    5748520|       438|        WA|             LOS|2016|    4|       20574|         20588|      20160430|         10292016|\n",
      "|    5748521|       438|        WA|             LOS|2016|    4|       20574|         20588|      20160430|         10292016|\n",
      "|    5748522|       464|        HI|             HHW|2016|    4|       20574|         20579|      20160430|         10292016|\n",
      "|    5748523|       464|        HI|             HHW|2016|    4|       20574|         20586|      20160430|         10292016|\n",
      "|    5748524|       464|        HI|             HHW|2016|    4|       20574|         20586|      20160430|         10292016|\n",
      "|    5748525|       464|        FL|             HOU|2016|    4|       20574|         20581|      20160430|         10292016|\n",
      "|    5748526|       464|        CA|             LOS|2016|    4|       20574|         20581|      20160430|         10292016|\n",
      "+-----------+----------+----------+----------------+----+-----+------------+--------------+--------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "travel.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create us_states Dimension Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_states_dim_schema = StructType([\n",
    "        StructField(\"State Code\", LongType()),\n",
    "        StructField(\"State\", StringType()),\n",
    "        StructField(\"Male Population\", LongType()),\n",
    "        StructField(\"Female Population\", StringType()),\n",
    "        StructField(\"Total Population\", StringType()),\n",
    "        StructField(\"Foreign-born\", StringType())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_states_spark = spark.read.options(delimiter=';',schema=us_states_dim_schema, header='True').csv('us-cities-demographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_states_stg = us_states_spark.select('State Code','State','Male Population','Female Population','Total Population','Foreign-born')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_states_stg = us_states_stg.createOrReplaceTempView(\"us_states_stg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_states_dim = spark.sql(\"\"\"SELECT \n",
    "                `State Code` as state_code, \n",
    "                first(State) as state, \n",
    "                sum(`Male Population`) as male_population,\n",
    "                sum(`Female Population`) AS female_population, \n",
    "                sum(`Total Population`) as total_population,\n",
    "                sum(`Foreign-born`) as foreign_born_population \n",
    "              FROM us_states_stg GROUP BY state_code \n",
    "              ORDER BY State\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+---------------+-----------------+----------------+-----------------------+\n",
      "|state_code|               state|male_population|female_population|total_population|foreign_born_population|\n",
      "+----------+--------------------+---------------+-----------------+----------------+-----------------------+\n",
      "|        AL|             Alabama|      2448200.0|        2715106.0|       5163306.0|               252541.0|\n",
      "|        AK|              Alaska|       764725.0|         728750.0|       1493475.0|               166290.0|\n",
      "|        AZ|             Arizona|    1.1137275E7|      1.1360435E7|      2.249771E7|              3411565.0|\n",
      "|        AR|            Arkansas|      1400724.0|        1482165.0|       2882889.0|               307753.0|\n",
      "|        CA|          California|    6.1055672E7|      6.2388681E7|    1.23444353E8|            3.7059662E7|\n",
      "|        CO|            Colorado|      7273095.0|        7405250.0|     1.4678345E7|              1688155.0|\n",
      "|        CT|         Connecticut|      2123435.0|        2231661.0|       4355096.0|              1114250.0|\n",
      "|        DE|            Delaware|       163400.0|         196385.0|        359785.0|                16680.0|\n",
      "|        DC|District of Columbia|      1598525.0|        1762615.0|       3361140.0|               475585.0|\n",
      "|        FL|             Florida|    1.5461937E7|      1.6626425E7|     3.2306132E7|              7845566.0|\n",
      "+----------+--------------------+---------------+-----------------+----------------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us_states_dim.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create country Dimension Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_dim_schema = StructType([\n",
    "        StructField(\"i94_res\", LongType()),\n",
    "        StructField(\"country\", StringType())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_spark = spark.read.options(delimiter=',',schema=country_dim_schema, header='True').csv('country_codes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_stg = country_spark.select('i94_res','country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_stg = country_stg.createOrReplaceTempView(\"country_stg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_dim = spark.sql(\"\"\"SELECT \n",
    "                cast(i94_res as int) as country_id, \n",
    "                country as country_name \n",
    "             FROM country_stg\n",
    "             ORDER BY country_name\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|country_id|   country_name|\n",
      "+----------+---------------+\n",
      "|       236|    AFGHANISTAN|\n",
      "|       101|        ALBANIA|\n",
      "|       316|        ALGERIA|\n",
      "|       102|        ANDORRA|\n",
      "|       324|         ANGOLA|\n",
      "|       529|       ANGUILLA|\n",
      "|       518|ANTIGUA-BARBUDA|\n",
      "|       687|      ARGENTINA|\n",
      "|       151|        ARMENIA|\n",
      "|       532|          ARUBA|\n",
      "+----------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_dim.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "+ Verify that there are no Null values in the key columns of any of the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(country_dim.filter(\"country_id is null\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(airports_dim.filter(\"airport_id is null\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(us_states_dim.filter(\"state_code is null\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(travelers_dim.filter(\"traveler_id is null\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(travel.filter(\"traveler_id is null\").count())\n",
    "print(travel.filter(\"country_id is null\").count())\n",
    "print(travel.filter(\"state_code is null\").count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "+ Check the counts of the tables and verify they match the count of records in the source table views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289\n",
      "8978\n",
      "49\n",
      "3077655\n",
      "2943721\n"
     ]
    }
   ],
   "source": [
    "print(country_dim.count())\n",
    "print(airports_dim.count())\n",
    "print(us_states_dim.count())\n",
    "print(travelers_dim.count())\n",
    "print(travel.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(country_dim=289)]\n",
      "[Row(airports_dim=8978)]\n",
      "[Row(us_states_dim=49)]\n",
      "[Row(travelers_dim=3077655)]\n",
      "[Row(travel=2943721)]\n"
     ]
    }
   ],
   "source": [
    "print(spark.sql(\"\"\"SELECT COUNT(1) as country_dim FROM (SELECT \n",
    "                cast(i94_res as int) as country_id, \n",
    "                country as country_name \n",
    "             FROM country_stg\n",
    "             ORDER BY country_name)\"\"\").collect())\n",
    "print(spark.sql(\"\"\"SELECT COUNT(1) as airports_dim FROM (SELECT \n",
    "                ident as airport_id, \n",
    "                iata_code, \n",
    "                type as airport_type, \n",
    "                name as airport_name, \n",
    "                municipality, \n",
    "                iso_region,\n",
    "                coordinates \n",
    "            FROM airports WHERE type in ('small_airport','medium_airport','large_airport','closed')\n",
    "            AND iata_code is not null)\"\"\").collect())\n",
    "print(spark.sql(\"\"\"SELECT COUNT(1) as us_states_dim FROM (SELECT \n",
    "                `State Code` as state_code, \n",
    "                first(State) as state, \n",
    "                sum(`Male Population`) as male_population,\n",
    "                sum(`Female Population`) AS female_population, \n",
    "                sum(`Total Population`) as total_population,\n",
    "                sum(`Foreign-born`) as foreign_born_population \n",
    "              FROM us_states_stg GROUP BY state_code \n",
    "              ORDER BY State)\"\"\").collect())\n",
    "print(spark.sql(\"\"\"SELECT COUNT(1) as travelers_dim FROM (SELECT \n",
    "                cast(cicid as bigint) as traveler_id, \n",
    "                cast(biryear as int) as birth_year, \n",
    "                cast(i94bir as int) as age, \n",
    "                gender, \n",
    "                airline, \n",
    "                fltno as flight_no, \n",
    "                visatype as visa_type \n",
    "              FROM travelers\n",
    "              WHERE airline is not null\n",
    "              OR fltno is not null)\"\"\").collect())\n",
    "print(spark.sql(\"\"\"SELECT COUNT(1) as travel FROM (SELECT\n",
    "                cast(cicid as bigint) as traveler_id, \n",
    "                cast(i94res as int) as country_id,\n",
    "                i94addr as state_code,\n",
    "                i94port as destination_city,\n",
    "                cast(i94yr as int) as year, \n",
    "                cast(i94mon as int) as month, \n",
    "                cast(arrdate as int) as arrival_date, \n",
    "                cast(depdate as int) as departure_date, \n",
    "                dtadfile as file_create_dt, \n",
    "                dtaddto as admitted_until_dt \n",
    "              FROM travel WHERE i94addr is not NULL\n",
    "              AND i94port is not null)\"\"\").collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "+ Verify key columns have unique values for all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289\n",
      "289\n"
     ]
    }
   ],
   "source": [
    "print(country_dim.select(\"country_id\").distinct().count())\n",
    "print(country_dim.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8978\n",
      "8978\n"
     ]
    }
   ],
   "source": [
    "print(airports_dim.select(\"airport_id\").distinct().count())\n",
    "print(airports_dim.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "print(us_states_dim.select(\"state_code\").distinct().count())\n",
    "print(us_states_dim.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3077655\n",
      "3077655\n"
     ]
    }
   ],
   "source": [
    "print(travelers_dim.select(\"traveler_id\").distinct().count())\n",
    "print(travelers_dim.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2943721\n",
      "2943721\n"
     ]
    }
   ],
   "source": [
    "print(travel.select(\"traveler_id\",\"country_id\",\"state_code\").distinct().count())\n",
    "print(travel.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Writing the final certified tables to Parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_dim.write.parquet(\"analytics_tables/country_dim/country_dim.parquet\",mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_states_dim.write.parquet(\"analytics_tables/us_states_dim/us_states_dim.parquet\",mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airports_dim.write.parquet(\"analytics_tables/airports_dim/airports_dim.parquet\",mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "travelers_dim.write.parquet(\"analytics_tables/travelers_dim/travelers_dim.parquet\",mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "travel.write.parquet(\"analytics_tables/travel/travel.parquet\",partitionBy=[\"year\",\"month\"], mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### The data dictionary and data model are included in the file `data_dictionary.xlsx`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Rationale for choosing Pandas for data exploration and Spark for ETL pipelines and data quality checks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "+ Pandas library was chosen for data exploration and analysis because Pandas stores data in local memory and is meant for working with smaller sets of data.\n",
    "\n",
    "+ For data transformations, cleaning, and ETL with the full data sets, Spark was chosen as it is optimized for working with large datasets and the tasks can be parallelized across the Spark cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### How often should the data be updated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "+ The data can be expected to be updated on a daily basis, with new records added to the `travel` Fact table and new travelers added to the `travelers` table as new unique records are identified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Changes in the approach for different scenarios:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.) The data was increased by 100x\n",
    "\n",
    "+ If the size of the data were to be increased by 100x, we could store the datasets in S3 which provides virtually unlimited storage capacity, we could add additional nodes to the Spark cluster, and we can use a cloud data warehouse such as Amazon Redshift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.) The data populates a dashboard that must be updated on a daily basis by 7am every day\n",
    "\n",
    "+ If the data populates a dashboard that must be updated by a certain time each day, Airflow can be used to schedule jobs which start each day with enough time to complete before 7am. The start time can be adjusted depending on how many resources are allocated and how much data is expected to be processed for that day's batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.) The database needed to be accessed by 100+ people\n",
    "\n",
    "+ If the database needed to be accessed by 100+ people, we could load the data into a managed data warehouse such as Amazon Redshift or Snowflake which are able to scale up depending on the amount of users and number of queries being run."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
